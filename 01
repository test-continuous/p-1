from bs4 import BeautifulSoup

def parse_html(html_content):
    """Optimized HTML parsing function to extract required details."""
    
    soup = BeautifulSoup(html_content, 'lxml')  # Use 'lxml' for speed

    # Find the first table efficiently
    table = soup.find('table')
    if not table:
        return None  # No table found, return None

    rows = table.find_all('tr')
    if len(rows) < 2:
        return None  # Not enough rows to process

    # Extract details using dictionary comprehension (avoiding redundant loops)
    details = {row.find_all('td')[0].text.strip(): row.find_all('td')[1].text.strip()
               for row in rows[1:] if len(row.find_all('td')) >= 2}

    # Ensure required fields exist
    required_fields = {'Component Name', 'Workload Type', 'Time of Execution', 
                       'Environment', 'Region', 'App Namespace'}
    if not required_fields.issubset(details):
        return None  # Skip invalid entries

    # Extract "Pod Checkout Status" & "Log Checkout Status" from text (efficiently)
    plain_text = soup.get_text(separator=' ')
    details['Pod Checkout Status'] = extract_status(plain_text, "Pod Checkout Status=")
    details['Log Checkout Status'] = extract_status(plain_text, "Log Checkout Status=")

    return details  # Return parsed details
